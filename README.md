# éŸ³é¢‘çœŸä¼ªæ£€æµ‹ç³»ç»Ÿ / Audio Authenticity Detection System
åŸºäº Flask + TensorFlow æ„å»ºçš„ç«¯åˆ°ç«¯éŸ³é¢‘çœŸä¼ªæ£€æµ‹ç³»ç»Ÿï¼Œæ”¯æŒ LSTM/Transformer åŒæ¨¡å‹è®­ç»ƒä¸æ¨ç†ï¼Œè¦†ç›–ã€Œæ•°æ®é¢„å¤„ç†â†’ç‰¹å¾æå–â†’æ¨¡å‹è®­ç»ƒâ†’å¯è§†åŒ–åˆ†æâ†’æ‰¹é‡é¢„æµ‹ã€å…¨æµç¨‹ï¼Œå¯é«˜æ•ˆè¯†åˆ«çœŸå®éŸ³é¢‘ä¸AIç”Ÿæˆä¼ªé€ éŸ³é¢‘ã€‚  
An end-to-end audio authenticity detection system built with Flask + TensorFlow, supporting dual-model (LSTM/Transformer) training and inference. It covers the full workflow of "Data Preprocessing â†’ Feature Extraction â†’ Model Training â†’ Visualization Analysis â†’ Batch Prediction", and can efficiently identify real audio and AI-generated fake audio.

## ğŸ“š ç›®å½• / Table of Contents
- [åŠŸèƒ½ç‰¹æ€§ (Functional Features)](#-åŠŸèƒ½ç‰¹æ€§)
- [ç¯å¢ƒè¦æ±‚ (Environment Requirements)](#-ç¯å¢ƒè¦æ±‚)
- [æ•°æ®é›†æ ¼å¼è¦æ±‚ (Dataset Format Requirements)](#-æ•°æ®é›†æ ¼å¼è¦æ±‚)
- [å¿«é€Ÿå¼€å§‹ (Quick Start)](#-å¿«é€Ÿå¼€å§‹)
- [æ ¸å¿ƒæ¨¡å—è¯´æ˜ (Core Module Description)](#-æ ¸å¿ƒæ¨¡å—è¯´æ˜)
- [Webç•Œé¢ä½¿ç”¨ (Web Interface Usage)](#-webç•Œé¢ä½¿ç”¨)
- [å¸¸è§é—®é¢˜ (FAQs)](#-å¸¸è§é—®é¢˜)
- [è”ç³»æˆ‘ä»¬ (Contact Us)](#-è”ç³»æˆ‘ä»¬)

## ğŸŒŸ åŠŸèƒ½ç‰¹æ€§ / Functional Features
| æ¨¡å— (Module)         | æ ¸å¿ƒèƒ½åŠ› (Core Capabilities)                                                                 |
|-----------------------|----------------------------------------------------------------------------------------------|
| æ•°æ®é¢„å¤„ç† (Data Preprocessing) | æ”¯æŒ wav/mp3/flac/m4a/webm å¤šæ ¼å¼éŸ³é¢‘ï¼›è‡ªåŠ¨æ ‡å‡†åŒ–é‡‡æ ·ç‡/æ—¶é•¿ï¼›ç”Ÿæˆç»“æ„åŒ–NPZæ•°æ® <br> Supports multi-format audio (wav/mp3/flac/m4a/webm); automatically standardizes sampling rate/duration; generates structured NPZ data |
| ç‰¹å¾æå– (Feature Extraction)   | æå–éŸ³é¢‘æ ¸å¿ƒå£°å­¦ç‰¹å¾ï¼šZCRï¼ˆè¿‡é›¶ç‡ï¼‰ã€RMSï¼ˆå‡æ–¹æ ¹èƒ½é‡ï¼‰ã€MFCCï¼ˆæ¢…å°”é¢‘ç‡å€’è°±ç³»æ•°ï¼‰ <br> Extracts core acoustic features of audio: ZCR (Zero Crossing Rate), RMS (Root Mean Square Energy), MFCC (Mel-Frequency Cepstral Coefficients) |
| æ¨¡å‹è®­ç»ƒ (Model Training)       | æ”¯æŒ LSTM/Transformer ä¸¤ç§æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼›è‡ªå®šä¹‰æ‰¹æ¬¡å¤§å°ã€è®­ç»ƒè½®æ•°ã€å­¦ä¹ ç‡ç­‰å‚æ•° <br> Supports two deep learning models (LSTM/Transformer); customizes batch size, training epochs, learning rate and other parameters |
| å¯è§†åŒ–åˆ†æ (Visualization Analysis) | ç”ŸæˆéŸ³é¢‘æ³¢å½¢å›¾ã€ç‰¹å¾çƒ­åŠ›å›¾ï¼ˆMFCC/å·®åˆ†MFCCï¼‰ã€ZCR/RMSæ—¶åŸŸæ›²çº¿ï¼›æ”¯æŒç»“æœå¯è§†åŒ–å±•ç¤º <br> Generates audio waveform plots, feature heatmaps (MFCC/differential MFCC), ZCR/RMS time-domain curves; supports visual display of results |
| é¢„æµ‹åŠŸèƒ½ (Prediction Function)   | å•æ–‡ä»¶é¢„æµ‹/æ–‡ä»¶å¤¹æ‰¹é‡é¢„æµ‹ï¼›å®æ—¶å±•ç¤ºé¢„æµ‹è¿›åº¦ã€ç½®ä¿¡åº¦åŠç»“æœåˆ†ç±» <br> Single-file prediction/batch prediction for folders; real-time display of prediction progress, confidence and result classification |
| Webå¯è§†åŒ–ç•Œé¢ (Web Visual Interface) | æ— ä»£ç æ“ä½œå…¨æµç¨‹ï¼›æ”¯æŒä»»åŠ¡è¿›åº¦ç›‘æ§ã€ç»“æœä¸€é”®å¯¼å‡ºã€å¯è§†åŒ–å›¾è¡¨æŸ¥çœ‹ <br> Code-free full-process operation; supports task progress monitoring, one-click result export, and visualization chart viewing |

## ğŸ“‹ ç¯å¢ƒè¦æ±‚ / Environment Requirements
### åŸºç¡€ç¯å¢ƒ / Basic Environment
- Python 3.8 ~ 3.10ï¼ˆæ¨è3.9ï¼Œå…¼å®¹TensorFlow 2.xï¼Œé¿å…3.11+çš„å…¼å®¹æ€§é—®é¢˜ï¼‰ <br> Python 3.8 ~ 3.10 (3.9 recommended, compatible with TensorFlow 2.x, avoid compatibility issues with 3.11+)
- æ“ä½œç³»ç»Ÿï¼šWindows 10+/Linux (Ubuntu 18.04+)/macOS 12+ <br> Operating System: Windows 10+/Linux (Ubuntu 18.04+)/macOS 12+
- ç¡¬ä»¶ï¼šCPU/GPUå‡å¯ï¼ˆGPUéœ€é…ç½®CUDA 11.2+ã€cuDNN 8.1+ï¼ŒåŠ é€Ÿæ¨¡å‹è®­ç»ƒï¼‰ <br> Hardware: CPU/GPU are both acceptable (GPU requires CUDA 11.2+ and cuDNN 8.1+ to accelerate model training)

### ä¾èµ–å·¥å…·ï¼ˆå¿…è£…ï¼‰ / Dependent Tools (Mandatory Installation)
#### 1. FFmpegï¼ˆå¤„ç†éWAVæ ¼å¼éŸ³é¢‘ï¼‰ / FFmpeg (Process non-WAV format audio)
- Windowsï¼šä¸‹è½½ [FFmpeg](https://ffmpeg.org/download.html)ï¼Œè§£å‹åå°†`bin`ç›®å½•æ·»åŠ åˆ°ç³»ç»Ÿç¯å¢ƒå˜é‡ <br> Windows: Download [FFmpeg](https://ffmpeg.org/download.html), unzip it and add the `bin` directory to the system environment variables
- Linuxï¼š`sudo apt update && sudo apt install ffmpeg`
- macOSï¼š`brew install ffmpeg`

#### 2. Pythonä¾èµ–å®‰è£… / Python Dependency Installation
```bash
# å…‹éš†é¡¹ç›® / Clone the project
git clone https://github.com/BuHuiNieLanKing/AudioForgeryDetection.git
cd AudioForgeryDetection

# å®‰è£…æ ¸å¿ƒä¾èµ– / Install core dependencies
pip install -r requirements.txt

# å®‰è£…dlibï¼ˆWindowsé¢„ç¼–è¯‘åŒ…ï¼ŒLinux/macOSå¯ç›´æ¥pip install dlibï¼‰ / Install dlib (precompiled package for Windows; Linux/macOS can directly use pip install dlib)
cd dlib
# é€‚é…Python3.8çš„é¢„ç¼–è¯‘åŒ…ï¼Œå…¶ä»–ç‰ˆæœ¬éœ€ä¸‹è½½å¯¹åº”whlæ–‡ä»¶ / Precompiled package for Python3.8; download the corresponding whl file for other versions
pip install dlib-19.19.0-cp38-cp38-win_amd64.whl
cd ..  # å›åˆ°é¡¹ç›®æ ¹ç›®å½• / Return to the project root directory
```

## ğŸ“Š æ•°æ®é›†æ ¼å¼è¦æ±‚ / Dataset Format Requirements
### 1. æ ¸å¿ƒç›®å½•ç»“æ„ / Core Directory Structure
æ•°æ®é›†éœ€æŒ‰ã€Œæ ¹ç›®å½• â†’ åˆ†ç±»å­ç›®å½•ã€çš„å±‚çº§ç»„ç»‡ï¼Œ**fake** ç›®å½•å­˜æ”¾ä¼ªé€ éŸ³é¢‘ï¼Œ**real** ç›®å½•å­˜æ”¾çœŸå®éŸ³é¢‘ï¼Œç¤ºä¾‹å¦‚ä¸‹ï¼š <br>
The dataset must be organized in the hierarchy of "Root Directory â†’ Classification Subdirectories". The **fake** directory stores fake audio, and the **real** directory stores real audio. Example:
```
F:\archive\small_dataset\small_dataset\training  # æ•°æ®é›†æ ¹ç›®å½•ï¼ˆå¯å‘½åä¸ºtrain/val/testing...ï¼‰ / Dataset root directory (can be named train/val/testing...)
â”œâ”€â”€ fake/                                       # ä¼ªé€ éŸ³é¢‘ç›®å½•ï¼ˆæ ‡ç­¾0ï¼‰ / Fake audio directory (label 0)
â”‚   â”œâ”€â”€ fake_audio_1.wav
â”‚   â”œâ”€â”€ fake_audio_2.mp3
â”‚   â””â”€â”€ ...ï¼ˆæ”¯æŒwav/mp3/flac/m4a/webmæ ¼å¼ï¼‰ / ... (supports wav/mp3/flac/m4a/webm formats)
â””â”€â”€ real/                                       # çœŸå®éŸ³é¢‘ç›®å½•ï¼ˆæ ‡ç­¾1ï¼‰ / Real audio directory (label 1)
    â”œâ”€â”€ real_audio_1.wav
    â”œâ”€â”€ real_audio_2.mp3
    â””â”€â”€ ...ï¼ˆæ”¯æŒwav/mp3/flac/m4a/webmæ ¼å¼ï¼‰ / ... (supports wav/mp3/flac/m4a/webm formats)
```

### 2. æ ¼å¼è§„èŒƒ / Format Specifications
- ç›®å½•å‘½åï¼šå¿…é¡»ä¸º `fake`ï¼ˆä¼ªé€ ï¼‰å’Œ `real`ï¼ˆçœŸå®ï¼‰ï¼ŒåŒºåˆ†å¤§å°å†™ï¼ˆå»ºè®®å…¨å°å†™ï¼‰ï¼› <br> Directory Naming: Must be `fake` (fake) and `real` (real), case-sensitive (all lowercase recommended);
- éŸ³é¢‘æ ¼å¼ï¼šæ”¯æŒ wav/mp3/flac/m4a/webmï¼Œé¢„å¤„ç†é˜¶æ®µä¼šè‡ªåŠ¨ç»Ÿä¸€æ ¼å¼ï¼› <br> Audio Format: Supports wav/mp3/flac/m4a/webm; the format will be automatically unified during preprocessing;
- è·¯å¾„è¦æ±‚ï¼šæ•°æ®é›†æ ¹ç›®å½•è·¯å¾„å»ºè®®ä¸ºç»å¯¹è·¯å¾„ï¼ˆå¦‚ `F:\archive\small_dataset\small_dataset\`ï¼‰ï¼Œé¿å…ä¸­æ–‡/ç©ºæ ¼ç‰¹æ®Šå­—ç¬¦ï¼› <br> Path Requirements: The root directory path of the dataset is recommended to be an absolute path (e.g., `F:\archive\small_dataset\small_dataset\`), avoiding Chinese/space special characters;
- æ•°æ®é›†åˆ’åˆ†ï¼šå»ºè®®æŒ‰ 7:2:1 åˆ’åˆ†è®­ç»ƒé›†ï¼ˆtrainï¼‰ã€éªŒè¯é›†ï¼ˆvalï¼‰ã€æµ‹è¯•é›†ï¼ˆtestingï¼‰ï¼Œå„å­é›†å‡éµå¾ªä¸Šè¿°ç›®å½•ç»“æ„ã€‚ <br> Dataset Division: It is recommended to divide into training set (train), validation set (val), and test set (testing) at a ratio of 7:2:1, and each subset follows the above directory structure.

### 3. é€‚é…ä¿®æ”¹ / Adaptation Modifications
åœ¨ `preprocess_data.py` ä¸­ä¿®æ”¹æ•°æ®é›†æ ¹ç›®å½•è·¯å¾„ï¼Œç¤ºä¾‹ï¼š <br>
Modify the dataset root directory path in `preprocess_data.py`, example:
```python
# åŸè·¯å¾„ / Original path
dataset_path = "./data/raw_audio"
# ä¿®æ”¹ä¸ºä½ çš„æ•°æ®é›†æ ¹ç›®å½• / Modify to your dataset root directory
dataset_path = r"F:\archive\small_dataset\small_dataset\testing"
```

## ğŸš€ å¿«é€Ÿå¼€å§‹ / Quick Start
### å‰ç½®å‡†å¤‡ / Preparations
1. ç¡®è®¤æ•°æ®é›†å·²æŒ‰ä¸Šè¿°æ ¼å¼å­˜æ”¾ï¼Œä¸”è·¯å¾„æ— ä¸­æ–‡/ç©ºæ ¼ï¼› <br> Confirm that the dataset is stored in the above format, and the path has no Chinese/space characters;
2. ä¿®æ”¹å„è„šæœ¬ä¸­çš„**è·¯å¾„é…ç½®**ï¼ˆå…³é”®ï¼ï¼‰ï¼š <br> Modify the **path configuration** in each script (critical!):
   - æ‰€æœ‰è„šæœ¬ä¸­ `feature_dir`/`audio_dir`/`save_dir` ç­‰è·¯å¾„ï¼Œæ›¿æ¢ä¸ºä½ æœ¬åœ°è·¯å¾„ï¼ˆå¦‚ `F:/AudioForgeryDetection/data/raw_audio`ï¼‰ï¼› <br> Replace paths such as `feature_dir`/`audio_dir`/`save_dir` in all scripts with your local path (e.g., `F:/AudioForgeryDetection/data/raw_audio`);
   - ç¤ºä¾‹ï¼š`feature_dir = './static/features'` â†’ `feature_dir = 'F:/AudioForgeryDetection/static/features'`ã€‚ <br> Example: `feature_dir = './static/features'` â†’ `feature_dir = 'F:/AudioForgeryDetection/static/features'`.

### åˆ†æ­¥æ‰§è¡Œï¼ˆå‘½ä»¤è¡Œï¼‰ / Step-by-Step Execution (Command Line)
#### 1. æ•°æ®é¢„å¤„ç† / Data Preprocessing
```bash
# æ ‡å‡†åŒ–éŸ³é¢‘æ ¼å¼ï¼Œç”Ÿæˆé¢„å¤„ç†åçš„NPZæ–‡ä»¶ / Standardize audio format and generate preprocessed NPZ files
python preprocess_data.py
```
![1.png](images/1.png)
- è¾“å‡ºï¼šé¢„å¤„ç†åçš„éŸ³é¢‘æ•°æ®ä¿å­˜è‡³ `./preprocessed_batches` ç›®å½• <br> Output: Preprocessed audio data is saved to the `./preprocessed_batches` directory

#### 2. ç‰¹å¾æå– / Feature Extraction
```bash
# æå–ZCR/RMS/MFCCç‰¹å¾ï¼Œä¿å­˜ä¸ºç‰¹å¾çŸ©é˜µ / Extract ZCR/RMS/MFCC features and save as feature matrix
python features.py
```
![2.png](images/2.png)
- è¾“å‡ºï¼šç‰¹å¾æ–‡ä»¶ä¿å­˜è‡³ `./features_batches` ç›®å½•ï¼ˆ.npzæ ¼å¼ï¼Œå«X_featuresç‰¹å¾çŸ©é˜µã€yæ ‡ç­¾ï¼‰ <br> Output: Feature files are saved to the `./features_batches` directory (.npz format, including X_features feature matrix and y labels)

#### 3. å¯è§†åŒ–åˆ†æ / Visualization Analysis
```bash
# å¯è§†åŒ–é¢„å¤„ç†åçš„éŸ³é¢‘æ³¢å½¢ / Visualize preprocessed audio waveforms
python showPreProcessed.py

# å¯è§†åŒ–ç‰¹å¾åˆ†å¸ƒï¼ˆMFCCçƒ­åŠ›å›¾ã€ZCR/RMSæ›²çº¿ã€MFCCå·®åˆ†å›¾ï¼‰ / Visualize feature distribution (MFCC heatmap, ZCR/RMS curve, MFCC differential map)
python showFeatures.py
```
![3.png](images/3.png)
![5.jpg](images/5.jpg)

![4.png](images/4.png)

![6.png](images/6.png)

![7.png](images/7.png)

![8.png](images/8.png)
- è¾“å‡ºï¼šå¯è§†åŒ–å›¾ç‰‡ä¿å­˜è‡³ `./audio_waveform_images,./feature_visualizations` ç›®å½•ï¼ŒæŒ‰ã€Œreal/fakeã€åˆ†ç±»å­˜å‚¨ <br> Output: Visualized images are saved to `./audio_waveform_images,./feature_visualizations` directories, stored by "real/fake" classification

#### 4. æ¨¡å‹è®­ç»ƒ / Model Training
```bash
# è®­ç»ƒLSTMæ¨¡å‹ / Train LSTM model
python trainLstm.py
# è®­ç»ƒTransformeræ¨¡å‹ / Train Transformer model
python trainTransformer.py
```
![9.png](images/9.png)

![16.png](images/16.png)
- è¾“å‡ºï¼šè®­ç»ƒå¥½çš„æ¨¡å‹ä¿å­˜è‡³ `models` ç›®å½•ï¼ˆ.h5æ ¼å¼ï¼‰ <br> Output: Trained models are saved to the `models` directory (.h5 format)

#### 5. æ‰¹é‡é¢„æµ‹ / Batch Prediction
```bash
# å¯¹ç›®æ ‡æ–‡ä»¶å¤¹å†…çš„éŸ³é¢‘è¿›è¡ŒçœŸä¼ªæ£€æµ‹ / Perform authenticity detection on audio in the target folder
python predict.py
```

Lstm æ¨¡å‹é¢„æµ‹ç»“æœ / LSTM Model Prediction Results
![10.png](images/10.png)
![11.png](images/11.png)

Transformer æ¨¡å‹é¢„æµ‹ç»“æœ / Transformer Model Prediction Results
![12.png](images/12.png)
![13.png](images/13.png)

- è¾“å…¥ï¼šéœ€é¢„æµ‹çš„éŸ³é¢‘æ–‡ä»¶å¤¹è·¯å¾„ï¼ˆåœ¨predict.pyä¸­é…ç½®ï¼‰ï¼› <br> Input: Path of the audio folder to be predicted (configured in predict.py);
- è¾“å‡ºï¼šå«æ–‡ä»¶åã€é¢„æµ‹æ ‡ç­¾ã€ç½®ä¿¡åº¦ã€‚ <br> Output: Includes file name, predicted label, and confidence.

## ğŸ–¥ï¸ Webç•Œé¢ä½¿ç”¨ / Web Interface Usage
### å¯åŠ¨WebæœåŠ¡ / Start Web Service
```bash
# è¿è¡ŒFlask Webåº”ç”¨ / Run Flask Web application
python app.py
```
![14.png](images/14.png)

![15.png](images/15.png)
### æ“ä½œæµç¨‹ / Operation Process
1. æµè§ˆå™¨è®¿é—® `http://localhost:5000`ï¼ˆé»˜è®¤ç«¯å£ï¼‰ï¼› <br> Access `http://localhost:5000` (default port) in the browser;
2. å·¦ä¾§å¯¼èˆªæ ä¾æ¬¡æ‰§è¡Œï¼š <br> Execute sequentially from the left navigation bar:
   - ã€Œæ•°æ®ä¸Šä¼ ã€ï¼šä¸Šä¼ å¾…å¤„ç†çš„éŸ³é¢‘æ–‡ä»¶ï¼› <br> "Data Upload": Upload audio files to be processed;
   - ã€Œæ•°æ®é¢„å¤„ç†ã€ï¼šç‚¹å‡»å¼€å§‹æŒ‰é’®ï¼Œç­‰å¾…é¢„å¤„ç†å®Œæˆï¼› <br> "Data Preprocessing": Click the start button and wait for preprocessing to complete;
   - ã€Œç‰¹å¾æå–ã€ï¼šè‡ªåŠ¨æå–å£°å­¦ç‰¹å¾ï¼› <br> "Feature Extraction": Automatically extract acoustic features;
   - ã€Œæ¨¡å‹è®­ç»ƒã€ï¼šé€‰æ‹©LSTM/Transformerï¼Œé…ç½®å‚æ•°åå¼€å§‹è®­ç»ƒï¼› <br> "Model Training": Select LSTM/Transformer, configure parameters and start training;
   - ã€Œå¯è§†åŒ–åˆ†æã€ï¼šæŸ¥çœ‹ç‰¹å¾çƒ­åŠ›å›¾ã€æ³¢å½¢å›¾ç­‰ï¼› <br> "Visualization Analysis": View feature heatmaps, waveform plots, etc.;
   - ã€Œé¢„æµ‹ã€ï¼šä¸Šä¼ éŸ³é¢‘æ–‡ä»¶ï¼Œå®æ—¶æŸ¥çœ‹é¢„æµ‹ç»“æœã€‚ <br> "Prediction": Upload audio files and view prediction results in real time.

## ğŸ“– æ ¸å¿ƒæ¨¡å—è¯´æ˜ / Core Module Description
| è„šæœ¬æ–‡ä»¶ (Script Files)   | æ ¸å¿ƒä½œç”¨ (Core Function)                                                                 |
|---------------------------|-----------------------------------------------------------------------------------------|
| preprocess_data.py        | éŸ³é¢‘æ ¼å¼æ ‡å‡†åŒ–ã€æ—¶é•¿è£å‰ªã€é‡‡æ ·ç‡ç»Ÿä¸€ï¼Œç”Ÿæˆæ¨¡å‹å¯è¯»å–çš„NPZæ•°æ® <br> Standardizes audio format, cuts duration, unifies sampling rate, and generates NPZ data readable by the model |
| features.py               | æå–ZCR/RMS/MFCCç‰¹å¾ï¼Œæ‹¼æ¥ä¸º15ç»´ç‰¹å¾çŸ©é˜µï¼ŒæŒ‰æ‰¹æ¬¡ä¿å­˜ä¸º.npzæ–‡ä»¶ <br> Extracts ZCR/RMS/MFCC features, splices into a 15-dimensional feature matrix, and saves as .npz files in batches |
| showPreProcessed.py       | å¯è§†åŒ–é¢„å¤„ç†åçš„éŸ³é¢‘æ³¢å½¢ï¼Œç›´è§‚æŸ¥çœ‹éŸ³é¢‘æ—¶åŸŸç‰¹å¾ <br> Visualizes preprocessed audio waveforms to intuitively view audio time-domain features |
| showFeatures.py           | å¯è§†åŒ–å£°å­¦ç‰¹å¾ï¼šMFCCçƒ­åŠ›å›¾ã€ZCR/RMSæ—¶åŸŸæ›²çº¿ã€MFCCä¸€é˜¶/äºŒé˜¶å·®åˆ†å›¾ <br> Visualizes acoustic features: MFCC heatmap, ZCR/RMS time-domain curve, MFCC first/second-order differential map |
| trainLstm.py              | åŸºäºLSTMç½‘ç»œè®­ç»ƒéŸ³é¢‘çœŸä¼ªåˆ†ç±»æ¨¡å‹ï¼Œé€‚åˆåºåˆ—ç‰¹å¾å»ºæ¨¡ <br> Trains audio authenticity classification model based on LSTM network, suitable for sequence feature modeling |
| trainTransformer.py       | åŸºäºTransformerçš„è‡ªæ³¨æ„åŠ›æœºåˆ¶è®­ç»ƒæ¨¡å‹ï¼Œæ•æ‰é•¿è·ç¦»ç‰¹å¾ä¾èµ– <br> Trains model based on Transformer's self-attention mechanism to capture long-distance feature dependencies |
| predict.py                | åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹ï¼Œæ”¯æŒå•æ–‡ä»¶/æ‰¹é‡éŸ³é¢‘é¢„æµ‹ï¼Œè¾“å‡ºåˆ†ç±»ç»“æœå’Œç½®ä¿¡åº¦ <br> Loads trained models, supports single-file/batch audio prediction, and outputs classification results and confidence |
| app.py                    | Flask WebæœåŠ¡å…¥å£ï¼Œå°è£…æ‰€æœ‰åŠŸèƒ½ä¸ºå¯è§†åŒ–ç•Œé¢ <br> Flask Web service entry, encapsulates all functions into a visual interface |


## ğŸ“ è”ç³»æˆ‘ä»¬ / Contact Us
- QQï¼š310720949
- é—®é¢˜åé¦ˆï¼šå¯åœ¨GitHubé¡¹ç›®ä¸‹æäº¤Issueï¼Œæˆ–é€šè¿‡QQåé¦ˆä½¿ç”¨è¿‡ç¨‹ä¸­çš„é—®é¢˜ <br> Feedback: You can submit an Issue under the GitHub project, or feedback problems during use via QQ

## ğŸ“„ è®¸å¯è¯ / License
æœ¬é¡¹ç›®ä»…ä¾›å­¦ä¹ å’Œç ”ç©¶ä½¿ç”¨ï¼Œç¦æ­¢ç”¨äºå•†ä¸šç”¨é€”ã€‚ <br> This project is for learning and research purposes only, and is prohibited for commercial use.

### æ€»ç»“ / Summary
1. æ–‡æ¡£å·²å…¨é¢é€‚é…ä¸­è‹±åŒè¯­ï¼Œä¿æŒåŸæœ‰ç»“æ„ã€ä»£ç å—å’Œå›¾ç‰‡å¼•ç”¨ä¸å˜ï¼Œä»…å¯¹æè¿°æ€§æ–‡å­—è¡¥å……è‹±æ–‡ç¿»è¯‘ï¼› <br> The document has been fully adapted to Chinese and English bilingual, keeping the original structure, code blocks and image references unchanged, only adding English translations to descriptive text.
2. æŠ€æœ¯æœ¯è¯­é‡‡ç”¨è¡Œä¸šé€šç”¨è‹±æ–‡è¡¨è¾¾ï¼ˆå¦‚MFCCã€LSTMã€Transformerï¼‰ï¼Œç¡®ä¿ä¸“ä¸šå‡†ç¡®æ€§ï¼› <br> Technical terms use industry-general English expressions (e.g., MFCC, LSTM, Transformer) to ensure professional accuracy.
3. ä¿ç•™æ‰€æœ‰æ“ä½œæŒ‡ä»¤å’Œè·¯å¾„é…ç½®ç¤ºä¾‹ï¼ŒåŒè¯­å¯¹ç…§ä¾¿äºå›½å†…å¤–ç”¨æˆ·ç†è§£å’Œä½¿ç”¨ã€‚ <br> All operation instructions and path configuration examples are retained, with bilingual comparison to facilitate understanding and use by users at home and abroad.